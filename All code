library(data.table)
library(ggplot2)
library(mlr3)
library(mlr3learners)
library(mlr3tuning)
library(mlr3mbo)
library(glmnet)
library(OpenML)
library(mlr3pipelines)
library(mlr3filters)
library(tidyr)
library(dplyr)
set.seed(732)

future::plan("multisession")

setwd("C:/Users/nicol/OneDrive - University of Copenhagen/Desktop/3 Ã¥r/IML/Aflevering 1")

data = fread("Motor vehicle insurance data.csv")


cond_1 = which(data$Distribution_channel != 1 & data$Distribution_channel != 0)
data$Distribution_channel[cond_1] = matrix(data= NA, nrow=length(cond_1))

#Initialize data
data$ID = as.factor(data$ID)
data$Distribution_channel = as.factor(data$Distribution_channel)
data$Payment = as.factor(data$Payment)
data$Type_risk = as.factor(data$Type_risk)
data$Area = as.factor(data$Area)
data$Second_driver = as.factor(data$Second_driver)
data$N_doors = as.factor(data$N_doors)
data$Type_fuel = as.factor(data$Type_fuel)

data$Date_start_contract = as.Date(data$Date_start_contract, format = "%d/%m/%Y")
data$Date_start_contract = as.numeric(data$Date_start_contract)
data$Date_birth = as.Date(data$Date_birth, format = "%d/%m/%Y")
data$Date_birth = as.numeric(data$Date_birth)
data$Date_driving_licence = as.Date(data$Date_driving_licence, format = "%d/%m/%Y")
data$Date_driving_licence = as.numeric(data$Date_driving_licence)

data_num = data[,lapply(.SD, mean, na.rm = TRUE), by = ID, .SDcols = is.numeric]
data_num = data_num[,-c("Lapse", "Premium", "N_claims_year", "N_claims_history")]
data_fac = data[,lapply(.SD, function(x) x[1]), by = ID, .SDcols = is.factor]
data = merge(data_num, data_fac[,-1], by = "ID")[,-1]










data_plot_fac = data_fac[,-c(1,2)] %>% pivot_longer(cols = everything(),
                                                    names_to = "covariates",
                                                    values_to = "level")

ggplot(data_plot_fac, aes(x = covariates, fill = as.factor(level))) + 
  geom_bar(position = "stack") +
  theme(plot.background = element_rect(fill = "#fafafa", color = NA),
        panel.background = element_rect(fill = "#fafafa"),
        legend.background = element_rect(fill = "#fafafa")) +
  labs(x = "Features", y = "Count", fill = "Level") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  scale_fill_manual(values = c(
    "7" = "#8c510a",
    "6" = "#01665e",
    "5" = "#bf812d",
    "4" = "#35978f",
    "3" = "#dfc27d",
    "2" = "#80cdc1",
    "1" = "#f6e8c3",
    "0" = "#c7eae5",
    
    "P" = "#543005",
    "D" = "#003c30",
    
    "NA" = "#f5f5f5"
  ))

#NA plot

na_count <- colSums(is.na(data))
na_data <- data.frame(
  variable = names(na_count),
  count = na_count
)
na_data <- na_data %>% filter(count>0)
length(data)
ggplot(na_data, aes(x=variable, y=count/(nrow(data)))) + geom_bar(stat="identity", fill="#f6e8c3", color="#dfc27d") +
  labs(x="Features countaining missing values", y="Proportion of the data") +
  theme(plot.background = element_rect(fill = "#fafafa", color = NA),
        panel.background = element_rect(fill = "#fafafa"),
        legend.background = element_rect(fill = "#fafafa"))


#Log transformed data of costs
ggplot(data, aes(x = log(Cost_claims_year))) + 
  geom_histogram(color = "#dfc27d", fill = "#f6e8c3") +
  theme(plot.background = element_rect(fill = "#fafafa", color = NA),
        panel.background = element_rect(fill = "#fafafa"),
        legend.background = element_rect(fill = "#fafafa"))

ggplot(data[data$Cost_claims_year > 0], aes(x = R_Claims_history)) + 
  geom_histogram(color = "#dfc27d", fill = "#f6e8c3") +
  theme(plot.background = element_rect(fill = "#fafafa", color = NA),
        panel.background = element_rect(fill = "#fafafa"),
        legend.background = element_rect(fill = "#fafafa"))

ggplot(data[data$Cost_claims_year > 0], aes(x = log(Cost_claims_year/R_Claims_history))) + 
  geom_histogram(color = "#dfc27d", fill = "#f6e8c3") +
  theme(plot.background = element_rect(fill = "#fafafa", color = NA),
        panel.background = element_rect(fill = "#fafafa"),
        legend.background = element_rect(fill = "#fafafa"))









#Transforming data to 
data_classif = data[, Claims := as.integer(Cost_claims_year > 0)]
data_classif = data_classif[,-c("Cost_claims_year", "R_Claims_history")]

data_freq = data[data$Cost_claims_year != 0 & data$R_Claims_history != 0]
data_freq = data_freq[,-c("Cost_claims_year","Claims")]

data_y = data[data$Cost_claims_year != 0 & data$R_Claims_history != 0]
data_y = data_y[, Claim_size := Cost_claims_year/R_Claims_history]
data_y = data_y[,-c("Cost_claims_year", "R_Claims_history")]


task_classif = as_task_classif(data, target="Claims")
task_classif$set_col_roles("Claims", c("target", "stratum"))

task_regr_freq = as_task_regr(data_freq, target="R_Claims_history")

task_regr_y = as_task_regr(data_y, target="Claim_size")


graph = po("imputemean", affect_columns = selector_name("Length")) %>>%  
  po("imputesample", affect_columns = selector_type("factor")) %>>% 
  po("encode") %>>% 
  po("scale")


#Classification learners
lrn_classif_featureless = as_learner(graph %>>% lrn("classif.featureless"))

lrn_classif_glmnet = as_learner(graph %>>% lrn("classif.glmnet", predict_type = "prob", s = to_tune(0,1), alpha = to_tune(0,1)))

at_classif_glmnet = auto_tuner(tuner = tnr("random_search", batch_size = 8),
                               learner = lrn_classif_glmnet,
                               resampling = rsmp("cv", folds = 3),
                               measure = msr("classif.auc"),
                               terminator = trm("evals", n_evals = 10))

lrn_classif_xgboost = as_learner(graph %>>% lrn("classif.xgboost", predict_type = "prob", eta = to_tune(0.1,0.3), nrounds = to_tune(100,500), max_depth = to_tune(1,10)))

at_classif_xgboost = auto_tuner(tuner = tnr("random_search", batch_size = 8),
                                learner = lrn_classif_xgboost,
                                resampling = rsmp("cv", folds = 3),
                                measure = msr("classif.auc"),
                                terminator = trm("evals", n_evals = 10))

lrn_classif_ranger = as_learner(graph %>>% lrn("classif.ranger", predict_type = "prob", mtry.ratio = to_tune(0.1,1), min.node.size = to_tune(p_int(1,50))))

at_classif_ranger = auto_tuner(tuner = tnr("random_search", batch_size = 8),
                               learner = lrn_classif_ranger,
                               resampling = rsmp("cv", folds = 3),
                               measure = msr("classif.auc"),
                               terminator = trm("evals", n_evals = 10))

#Regression learners
lrn_regr_featureless = as_learner(graph_classif %>>% lrn("regr.featureless"))

lrn_regr_log = as_learner(ppl("targettrafo",
                              graph = as_learner(graph_classif %>>% lrn("regr.lm")),
                              targetmutate.trafo = function(x) log(x),
                              targetmutate.inverter = function(x) list(response = exp(x$response))))

lrn_regr_glmnet = as_learner(graph_classif %>>% lrn("regr.glmnet", s = to_tune(0,1), alpha = to_tune(0,1)))

at_regr_glmnet = auto_tuner(tuner = tnr("random_search", batch_size = 8),
                            learner = lrn_regr_glmnet,
                            resampling = rsmp("cv", folds = 3),
                            measure = msr("regr.mae"),
                            terminator = trm("evals", n_evals = 10))

lrn_regr_glmnet_log = ppl("targettrafo",
                          graph = as_learner(graph_classif %>>% lrn("regr.glmnet", s = to_tune(0,1), alpha = to_tune(0,1))),
                          targetmutate.trafo = function(x) log(x),
                          targetmutate.inverter = function(x) list(response = exp(x$response)))

at_regr_glmnet_log = auto_tuner(tuner = tnr("random_search", batch_size = 8),
                                learner = lrn_regr_glmnet_log,
                                resampling = rsmp("cv", folds = 3),
                                measure = msr("regr.mae"),
                                terminator = trm("evals", n_evals = 10))

lrn_regr_glmnet_poi = as_learner(graph_classif %>>% lrn("regr.glmnet", s = to_tune(0,1), alpha = to_tune(0,1), family = "poisson"))

at_regr_glmnet_poi = auto_tuner(tuner = tnr("random_search", batch_size = 8),
                                learner = lrn_regr_glmnet_poi,
                                resampling = rsmp("cv", folds = 3),
                                measure = msr("regr.mae"),
                                terminator = trm("evals", n_evals = 10))

lrn_regr_xgboost = as_learner(graph_classif %>>% lrn("regr.xgboost", eta = to_tune(0.1,0.3), nrounds = to_tune(100,500), max_depth = to_tune(1,10)))

at_regr_xgboost = auto_tuner(tuner = tnr("random_search", batch_size = 8),
                             learner = lrn_regr_xgboost,
                             resampling = rsmp("cv", folds = 3),
                             measure = msr("regr.mae"),
                             terminator = trm("evals", n_evals = 10))

lrn_regr_xgboost_log = ppl("targettrafo",
                           graph = as_learner(graph_classif %>>% lrn("regr.xgboost", eta = to_tune(0.1,0.3), nrounds = to_tune(100,500), max_depth = to_tune(1,10))),
                           targetmutate.trafo = function(x) log(x),
                           targetmutate.inverter = function(x) list(response = exp(x$response)))

at_regr_xgboost_log = auto_tuner(tuner = tnr("random_search", batch_size = 8),
                                 learner = lrn_regr_xgboost_log,
                                 resampling = rsmp("cv", folds = 3),
                                 measure = msr("regr.mae"),
                                 terminator = trm("evals", n_evals = 10))

lrn_regr_ranger = as_learner(graph_classif %>>% lrn("regr.ranger", mtry.ratio = to_tune(0.1,1), min.node.size = to_tune(p_int(1,50))))

at_regr_ranger = auto_tuner(tuner = tnr("random_search", batch_size = 8),
                            learner = lrn_regr_ranger,
                            resampling = rsmp("cv", folds = 3),
                            measure = msr("regr.mae"),
                            terminator = trm("evals", n_evals = 10))

lrn_regr_ranger_log = ppl("targettrafo", graph = as_learner(graph_classif %>>% lrn("regr.ranger", mtry.ratio = to_tune(0.1,1), min.node.size = to_tune(p_int(1,50)))),
                                                targetmutate.trafo = function(x) log(x),
                                                targetmutate.inverter = function(x) list(response = exp(x$response)))

at_regr_ranger_log = auto_tuner(tuner = tnr("random_search", batch_size = 8),
                            learner = lrn_regr_ranger_log,
                            resampling = rsmp("cv", folds = 3),
                            measure = msr("regr.mae"),
                            terminator = trm("evals", n_evals = 10))

#Renamaming the different learners
lrn_classif_featureless$id = "classif featureless"
lrn_classif_logreg$id = "classif logreg"
at_classif_glmnet$id = "auto classif glmnet"
at_classif_ranger$id = "auto classif ranger"
at_classif_xgboost$id = "auto classif xgboost"
lrn_regr_featureless$id = "regr featureless"

lrn_regr_log$id = "regr log"
at_regr_glmnet$id = "auto regr glmnet"
at_regr_glmnet_log$id = "auto regr glmnet log"
at_regr_glmnet_poi$id = "auto regr glmnet poisson"
at_regr_ranger$id = "auto regr ranger"
at_regr_ranger_log$id = "auto regr ranger"
at_regr_xgboost$id = "auto regr xgboost"
at_regr_xgboost_log$id = "auto regr xgboost log"


#Classification benchmark grid
design_classif = benchmark_grid(
  tasks = task_classif,
  learners = list(lrn_classif_featureless, lrn_classif_logreg, at_classif_glmnet, 
                  at_classif_ranger, at_classif_xgboost),
  resamplings = rsmp("cv", folds = 3)
)

#Classification results
results = benchmark(design = design_classif)
results$aggregate(list(msr("classif.auc"),,
                       msr("classif.bbrier")))

#Regression benchmark grid
design_regr_freq = benchmark_grid(
  tasks = task_regr_freq,
  learners = list(lrn_regr_featureless, at_regr_glmnet_poi, at_regr_glmnet, at_regr_ranger, at_regr_xgboost),
  resamplings = rsmp("cv", folds = 3)
)

design_regr_y = benchmark_grid(
  tasks = task_regr_y,
  learners = list(lrn_regr_featureless, lrn_regr_log, at_regr_glmnet_log, at_regr_ranger, at_regr_ranger_log, at_regr_xgboost, at_regr_xgboost_log),
  resamplings = rsmp("cv", folds = 3)
)

#Regression results
results_freq = benchmark(design = design_regr_freq)
results_freq$aggregate(list(msr("regr.mse"),
                         msr("regr.mae")))

results_y = benchmark(design = design_regr_y)
results_y$aggregate(list(msr("regr.mae"),
                         msr("regr.mape"),
                         msr("regr.rmsle")))

